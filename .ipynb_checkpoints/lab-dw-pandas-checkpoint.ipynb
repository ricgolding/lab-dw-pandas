{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1973e9e-8be6-4039-b70e-d73ee0d94c99",
   "metadata": {},
   "source": [
    "In this lab, we will be working with the customer data from an insurance company, which can be found in the CSV file located at the following link: https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "The data includes information such as customer ID, state, gender, education, income, and other variables that can be used to perform various analyses.\n",
    "\n",
    "Throughout the lab, we will be using the pandas library in Python to manipulate and analyze the data. Pandas is a powerful library that provides various data manipulation and analysis tools, including the ability to load and manipulate data from a variety of sources, including CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045146f-f4f7-44d9-8cd9-130d6400c73a",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "- Customer - Customer ID\n",
    "\n",
    "- ST - State where customers live\n",
    "\n",
    "- Gender - Gender of the customer\n",
    "\n",
    "- Education - Background education of customers \n",
    "\n",
    "- Customer Lifetime Value - Customer lifetime value(CLV) is the total revenue the client will derive from their entire relationship with a customer. In other words, is the predicted or calculated value of a customer over their entire duration as a policyholder with the insurance company. It is an estimation of the net profit that the insurance company expects to generate from a customer throughout their relationship with the company. Customer Lifetime Value takes into account factors such as the duration of the customer's policy, premium payments, claim history, renewal likelihood, and potential additional services or products the customer may purchase. It helps insurers assess the long-term profitability and value associated with retaining a particular customer.\n",
    "\n",
    "- Income - Customers income\n",
    "\n",
    "- Monthly Premium Auto - Amount of money the customer pays on a monthly basis as a premium for their auto insurance coverage. It represents the recurring cost that the insured person must pay to maintain their insurance policy and receive coverage for potential damages, accidents, or other covered events related to their vehicle.\n",
    "\n",
    "- Number of Open Complaints - Number of complaints the customer opened\n",
    "\n",
    "- Policy Type - There are three type of policies in car insurance (Corporate Auto, Personal Auto, and Special Auto)\n",
    "\n",
    "- Vehicle Class - Type of vehicle classes that customers have Two-Door Car, Four-Door Car SUV, Luxury SUV, Sports Car, and Luxury Car\n",
    "\n",
    "- Total Claim Amount - the sum of all claims made by the customer. It represents the total monetary value of all approved claims for incidents such as accidents, theft, vandalism, or other covered events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72419b-20fc-4905-817a-8c83abc59de6",
   "metadata": {},
   "source": [
    "External Resources: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ece17-e919-4e23-96c0-c7c59778436a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the data\n",
    "\n",
    "In this challenge, you will use pandas to explore a given dataset. Your task is to gain a deep understanding of the data by analyzing its characteristics, dimensions, and statistical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91437bd5-59a6-49c0-8150-ef0e6e6eb253",
   "metadata": {},
   "source": [
    "- Identify the dimensions of the dataset by determining the number of rows and columns it contains.\n",
    "- Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable. You should also provide suggestions for fixing any incorrect data types.\n",
    "- Identify the number of unique values for each column and determine which columns appear to be categorical. You should also describe the unique values of each categorical column and the range of values for numerical columns, and give your insights.\n",
    "- Compute summary statistics such as mean, median, mode, standard deviation, and quartiles to understand the central tendency and distribution of the data for numerical columns. You should also provide your conclusions based on these summary statistics.\n",
    "- Compute summary statistics for categorical columns and providing your conclusions based on these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dd4e8cd8-a6f6-486c-a5c4-1745b0c035f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows is 4008 and the number of columns is: 11\n",
      "The number of dimensions is: 2\n",
      "\n",
      "Data Types:\n",
      "Customer                      object\n",
      "ST                            object\n",
      "GENDER                        object\n",
      "Education                     object\n",
      "Customer Lifetime Value       object\n",
      "Income                       float64\n",
      "Monthly Premium Auto         float64\n",
      "Number of Open Complaints     object\n",
      "Policy Type                   object\n",
      "Vehicle Class                 object\n",
      "Total Claim Amount           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv')\n",
    "\n",
    "#Identify the dimensions of the dataset by determining the number of rows and columns it contains.\n",
    "rows = data.shape[0]\n",
    "columns = data.shape[1]\n",
    "\n",
    "print(f\"The number of rows is {rows} and the number of columns is: {columns}\")\n",
    "print(f\"The number of dimensions is: {data.ndim}\")\n",
    "\n",
    "#Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable. \n",
    "#You should also provide suggestions for fixing any incorrect data types.\n",
    "types = data.dtypes\n",
    "print(\"\\nData Types:\")\n",
    "print(types)\n",
    "#Suggestion: the customer lifetime value and number of open complaints columns have'object' as its data type but it should be float.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab51b5e5-c99b-466e-8c71-24fe3f87ac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Unique Values in Each Column:\n",
      "\n",
      "Categorical Columns:\n",
      "['Customer', 'ST', 'GENDER', 'Education', 'Customer Lifetime Value', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class']\n",
      "\n",
      "Numerical Columns:\n",
      "Index(['Income', 'Monthly Premium Auto', 'Total Claim Amount'], dtype='object')\n",
      "\n",
      "Unique Values for Categorical Columns:\n",
      "\n",
      "Column 'Customer':\n",
      "['RB50392' 'QZ44356' 'AI49188' ... 'CW49887' 'MY31220' nan]\n",
      "\n",
      "Column 'ST':\n",
      "['Washington' 'Arizona' 'Nevada' 'California' 'Oregon' 'Cali' 'AZ' 'WA'\n",
      " nan]\n",
      "\n",
      "Column 'GENDER':\n",
      "[nan 'F' 'M' 'Femal' 'Male' 'female']\n",
      "\n",
      "Column 'Education':\n",
      "['Master' 'Bachelor' 'High School or Below' 'College' 'Bachelors' 'Doctor'\n",
      " nan]\n",
      "\n",
      "Column 'Customer Lifetime Value':\n",
      "[nan '697953.59%' '1288743.17%' ... '2031499.76%' '323912.47%'\n",
      " '899704.02%']\n",
      "\n",
      "Column 'Number of Open Complaints':\n",
      "['1/0/00' '1/2/00' '1/1/00' '1/3/00' '1/5/00' '1/4/00' nan]\n",
      "\n",
      "Column 'Policy Type':\n",
      "['Personal Auto' 'Corporate Auto' 'Special Auto' nan]\n",
      "\n",
      "Column 'Vehicle Class':\n",
      "['Four-Door Car' 'Two-Door Car' 'SUV' 'Luxury SUV' 'Sports Car'\n",
      " 'Luxury Car' nan]\n",
      "\n",
      "Range of Values for Numerical Columns:\n",
      "Column 'Income' has a range of 0.0 to 99960.0.\n",
      "Column 'Monthly Premium Auto' has a range of 61.0 to 35354.0.\n",
      "Column 'Total Claim Amount' has a range of 0.382107 to 2893.239678.\n"
     ]
    }
   ],
   "source": [
    "#Identify the number of unique values for each column and determine which columns appear to be categorical. \n",
    "#You should also describe the unique values of each categorical column and \n",
    "#the range of values for numerical columns, and give your insights.\n",
    "nunique = data.nunique()\n",
    "print(\"\\nNumber of Unique Values in Each Column:\")\n",
    "categorical_cols = [col for col in data.columns if data[col].dtype == 'object' or nunique[col] <= 5]\n",
    "numerical_cols = data.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "print(\"\\nCategorical Columns:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "print(\"\\nNumerical Columns:\")\n",
    "print(numerical_cols)\n",
    "\n",
    "print(\"\\nUnique Values for Categorical Columns:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nColumn '{col}':\")\n",
    "    print(data[col].unique())\n",
    "\n",
    "print(\"\\nRange of Values for Numerical Columns:\")\n",
    "for col in numerical_cols:\n",
    "    min_val = data[col].min()\n",
    "    max_val = data[col].max()\n",
    "    print(f\"Column '{col}' has a range of {min_val} to {max_val}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bfd4df8b-c757-4219-a016-7c6c91775c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Statistical Summary for Numerical Columns:\n",
      "\n",
      "Statistics for 'Income':\n",
      "Mean: 39295.70121381886\n",
      "Median: 36234.0\n",
      "Mode: [0.0]\n",
      "Standard Deviation: 30469.42706040185\n",
      "25th Percentile: 14072.0\n",
      "75th Percentile: 64631.0\n",
      "\n",
      "Statistics for 'Monthly Premium Auto':\n",
      "Mean: 193.234360410831\n",
      "Median: 83.0\n",
      "Mode: [65.0]\n",
      "Standard Deviation: 1601.190368577621\n",
      "25th Percentile: 68.0\n",
      "75th Percentile: 109.5\n",
      "\n",
      "Statistics for 'Total Claim Amount':\n",
      "Mean: 404.98690940896364\n",
      "Median: 354.729129\n",
      "Mode: [321.6]\n",
      "Standard Deviation: 293.0272599264041\n",
      "25th Percentile: 202.157702\n",
      "75th Percentile: 532.8\n"
     ]
    }
   ],
   "source": [
    "#Compute summary statistics such as mean, median, mode, standard deviation, and quartiles to understand the central tendency and distribution of the data for numerical columns. \n",
    "#You should also provide your conclusions based on these summary statistics.\n",
    "\n",
    "print(\"\\n Statistical Summary for Numerical Columns:\")\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\nStatistics for '{col}':\")\n",
    "    print(f\"Mean: {data[col].mean()}\")\n",
    "    print(f\"Median: {data[col].median()}\")\n",
    "    print(f\"Mode: {data[col].mode().tolist()}\")\n",
    "    print(f\"Standard Deviation: {data[col].std()}\")\n",
    "    print(f\"25th Percentile: {data[col].quantile(0.25)}\")\n",
    "    print(f\"75th Percentile: {data[col].quantile(0.75)}\")\n",
    "\n",
    "#Income: the median income for this population is 36,234.00 and has a standard deviation of 30,469 meaning that\n",
    "#each individual is on average 30,469 off from the mean. The mode is 0 which emphasizes the reason why the\n",
    "#standard deviation is so far off the mean. The mean is 39,295 which is not too far away from the mean;\n",
    "#therefore the population is fairly even in terms of income and not many outliers.\n",
    "#75% of this population earns at least 14,072 and on the other hand the 25% earns 65,631\n",
    "\n",
    "#Monthly Premium Auto: There seems to be several outliers that are pulling the mean away for an average of 193.23\n",
    "#where the median shows a more accurate view of 83 paid monthly for premium auto. The most common payment is 65.\n",
    "#75% of this population pays 68 whereas 25% pays higher at 110.\n",
    "\n",
    "#Total Claim Amount: individuals in this population often claim 321.6 and the median is 354.72. Though on average,\n",
    "#each individual claims 405 though there must be some outliers that are interfering with this calculation.\n",
    "#the 75% of this population claims at least 202 whereas the 25% claims at least 533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c782966d-4417-4613-b1e2-5d38b8294b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>ST</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>Education</th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Number of Open Complaints</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Vehicle Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1071</td>\n",
       "      <td>1071</td>\n",
       "      <td>954</td>\n",
       "      <td>1071</td>\n",
       "      <td>1068</td>\n",
       "      <td>1071</td>\n",
       "      <td>1071</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1071</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1027</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>RB50392</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>F</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>445811.34%</td>\n",
       "      <td>1/0/00</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Four-Door Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>457</td>\n",
       "      <td>324</td>\n",
       "      <td>4</td>\n",
       "      <td>830</td>\n",
       "      <td>780</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Customer      ST GENDER Education Customer Lifetime Value  \\\n",
       "count      1071    1071    954      1071                    1068   \n",
       "unique     1071       8      5         6                    1027   \n",
       "top     RB50392  Oregon      F  Bachelor              445811.34%   \n",
       "freq          1     320    457       324                       4   \n",
       "\n",
       "       Number of Open Complaints    Policy Type  Vehicle Class  \n",
       "count                       1071           1071           1071  \n",
       "unique                         6              3              6  \n",
       "top                       1/0/00  Personal Auto  Four-Door Car  \n",
       "freq                         830            780            576  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute summary statistics for categorical columns and providing your conclusions based on these statistics.\n",
    "\n",
    "data[categorical_cols].describe()\n",
    "#There is 5 different types of genders, 3 types of vehicles. \n",
    "#Most of the individuals have a bachelor's and the predominant state is Oregon\n",
    "#The most frequent car insured is a Four-Door-Car and the type of policy is Personal Auto.\n",
    "#Most of the insured individuals are females."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a703890-63db-4944-b7ab-95a4f8185120",
   "metadata": {},
   "source": [
    "## Challenge 2: analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776a403-c56a-452f-ac33-5fd4fdb06fc7",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbc484-da4d-4f9c-9343-e1d44311a87e",
   "metadata": {},
   "source": [
    "The marketing team wants to know the top 5 less common customer locations. Create a pandas Series object that contains the customer locations and their frequencies, and then retrieve the top 5 less common locations in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2dca5073-4520-4f42-9390-4b92733284ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST\n",
      "Oregon        320\n",
      "California    211\n",
      "Arizona       186\n",
      "Cali          120\n",
      "Nevada         98\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "location_freq = data['ST'].value_counts()\n",
    "top5_less_common = location_freq.head(5)\n",
    "top5_less_common_series = pd.Series(top5_less_common)\n",
    "print(top5_less_common_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce80f43-4afa-43c7-a78a-c917444da4e0",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The sales team wants to know the total number of policies sold for each type of policy. Create a pandas Series object that contains the policy types and their total number of policies sold, and then retrieve the policy type with the highest number of policies sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f13997-1555-4f98-aca6-970fda1d2c3f",
   "metadata": {},
   "source": [
    "*Hint:*\n",
    "- *Using value_counts() method simplifies this analysis.*\n",
    "- *Futhermore, there is a method that returns the index of the maximum value in a column or row.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bcfad6c1-9af2-4b0b-9aa9-0dc5c17473c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total number of policies sold for each policy:\n",
      "Policy Type\n",
      "Personal Auto     780\n",
      "Corporate Auto    234\n",
      "Special Auto       57\n",
      "Name: count, dtype: int64\n",
      "The policy with the highest number of policies sold is Personal Auto with 780 policies sold\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "total = pd.Series(data['Policy Type']).value_counts()\n",
    "print(\"\\nThe total number of policies sold for each policy:\")\n",
    "print(total)\n",
    "max_policy = total.idxmax()\n",
    "max_policy_count = total.max()\n",
    "print(f\"The policy with the highest number of policies sold is {max_policy} with {max_policy_count} policies sold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b863fd3-bf91-4d5d-86eb-be29ed9f5b70",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The sales team wants to know if customers with Personal Auto have a lower income than those with Corporate Auto. How does the average income compare between the two policy types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1386d75-2810-4aa1-93e0-9485aa12d552",
   "metadata": {},
   "source": [
    "- Use *loc* to create two dataframes: one containing only Personal Auto policies and one containing only Corporate Auto policies.\n",
    "- Calculate the average income for each policy.\n",
    "- Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0563cf-6f8b-463d-a321-651a972f82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b16c27-f4a5-4727-a229-1f88671cf4e2",
   "metadata": {},
   "source": [
    "### Bonus: Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac584986-299b-475f-ac2e-928c16c3f512",
   "metadata": {},
   "source": [
    "Your goal is to identify customers with a high policy claim amount.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Review again the statistics for total claim amount to gain an understanding of the data.\n",
    "- To identify potential areas for improving customer retention and profitability, we want to focus on customers with a high policy claim amount. Consider customers with a high policy claim amount to be those in the top 25% of the total claim amount. Create a pandas DataFrame object that contains information about customers with a policy claim amount greater than the 75th percentile.\n",
    "- Use DataFrame methods to calculate summary statistics about the high policy claim amount data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3af5f1-6023-4b05-9c01-d05392daa650",
   "metadata": {},
   "source": [
    "*Note: When analyzing data, we often want to focus on certain groups of values to gain insights. Percentiles are a useful tool to help us define these groups. A percentile is a measure that tells us what percentage of values in a dataset are below a certain value. For example, the 75th percentile represents the value below which 75% of the data falls. Similarly, the 25th percentile represents the value below which 25% of the data falls. When we talk about the top 25%, we are referring to the values that fall above the 75th percentile, which represent the top quarter of the data. On the other hand, when we talk about the bottom 25%, we are referring to the values that fall below the 25th percentile, which represent the bottom quarter of the data. By focusing on these groups, we can identify patterns and trends that may be useful for making decisions and taking action.*\n",
    "\n",
    "*Hint: look for a method that gives you the percentile or quantile 0.75 and 0.25 for a Pandas Series.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d234634-50bd-41e0-88f7-d5ba684455d1",
   "metadata": {},
   "source": [
    "*Hint 2: check `Boolean selection according to the values of a single column` in https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731bca6-a760-4860-a27b-a33efa712ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
